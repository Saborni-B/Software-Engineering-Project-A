{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189566e5-bfbf-49b6-b8ac-2e22e08b2c94",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Please provide your inputs as followed:\n",
    "\n",
    "- **start_date**: The start date of your period of interest in the format **dd mm YYYY**\n",
    "- **end_date**: The end date of your period of interestin the format **dd mm YYYY**\n",
    "- **region**: The region of interest. Please provide this in a **bounding box format** (e.g. [10, -5, 25, 20]) or a **country name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783d61f-01e2-4875-a631-17d26ec593f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = \"2023 08 20\"\n",
    "end_date = \"2023 08 25\"\n",
    "region = \"Australia\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff4d30-8935-433a-a679-cabe9735d126",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100be2d0-a15e-457f-a512-af36c146107e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time\n",
    "import json\n",
    "import stackstac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49557f2-efbb-45dd-8b47-14575ee37f6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Starting up PySTAC client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873fc4cf-dc86-4ec2-9965-b307be4b942d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize PySTAC client for data query\n",
    "planetary_computer.set_subscription_key(\"c27669c4bdec434d804e2bd738cb16fc\")\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54dfcc1-5cfe-477a-9701-dcc13b99523f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced209b-3a55-4382-b5fd-5cc6547d828e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Processing of user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert date format \n",
    "def convert_format_date(input_date):\n",
    "    correct_formats = [\"%d %m %Y\", \"%Y %m %d\", \"%d/%m/%Y\", \"%Y/%m/%d\", \"%d-%m-%Y\", \"%Y-%m-%d\"]\n",
    "    \n",
    "    for format_str in correct_formats:\n",
    "        try:\n",
    "            date_obj = datetime.strptime(input_date, format_str)\n",
    "            formatted_date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "            return formatted_date\n",
    "        except ValueError: # Raised if input format is not compatible with set standard \n",
    "            pass\n",
    "    \n",
    "    raise ValueError(\"Invalid data format\")\n",
    "\n",
    "# Convert user start date format\n",
    "try:\n",
    "    start_date = convert_format_date(start_date)\n",
    "except ValueError:\n",
    "    print(\"Invalid start date format. Please check the acceptable formats\")\n",
    "            \n",
    "# Convert user end date format\n",
    "try:\n",
    "    end_date = convert_format_date(end_date)\n",
    "except ValueError:\n",
    "    print(\"Invalid end date format. Please check the acceptable formats\")\n",
    "\n",
    "date_period = start_date + \"/\" + end_date \n",
    "print(date_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80047f2f-aa0e-45f8-88ca-de1012401d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = np.arange(np.datetime64(start_date), np.datetime64(end_date))\n",
    "date_range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f6fc7-19bb-4a46-99d0-76edd5e4c59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_difference = (np.datetime64(end_date) - np.datetime64(start_date)).astype(int)\n",
    "time_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e9890-ea3b-42a5-9ae0-0bfbcdb76917",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Search for product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9f9c1-05d8-4451-8062-2959faa7748c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Search based on country input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe977dbb-9533-40f4-aa1f-9114b78c9415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get geopandas in-built naturalearth_lowres dataset\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee7679-1b47-403c-b233-33d7fd91d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = world[world[\"name\"] == region]\n",
    "ROI_bbox = ROI.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_catalog(region, date_period):\n",
    "    search_parameters = {\n",
    "        \"collections\": \"sentinel-5p-l2-netcdf\",\n",
    "        \"datetime\": date_period,\n",
    "        \"query\": {\"s5p:processing_mode\": {\"eq\": \"OFFL\"}, \"s5p:product_name\": {\"eq\": \"\"}},\n",
    "    }\n",
    "   \n",
    "    #bbox input\n",
    "    if isinstance(region, list) and len(region) == 4:\n",
    "        min_long, min_lat, max_long, max_lat = region\n",
    "        #-180 to 180 for longitudes, -90 to 90 for latitudes\n",
    "        long = all(-180 <= coordinates <= 180 for coordinates in [min_long, max_long]) \n",
    "        lat = all(-90 <= coordinates <= 90 for coordinates in [min_lat, max_lat])\n",
    "        \n",
    "        if long and lat:\n",
    "            search_parameters[\"bbox\"] = region\n",
    "        elif not long:\n",
    "            raise ValueError(\"Invalid longitudes in bbox\")\n",
    "        elif not lat:\n",
    "            raise ValueError(\"Invalid latitudes in bbox\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid coordinates in bbox\")\n",
    "        \n",
    "    else:\n",
    "        if ROI.empty: # Raise error if invalid region input\n",
    "            raise ValueError(\"Invalid country name\")\n",
    "        \n",
    "        gjson = json.loads(ROI.to_json())\n",
    "        coordinates = gjson[\"features\"][0][\"geometry\"][\"coordinates\"]\n",
    "        \n",
    "        if not isinstance(coordinates, list): \n",
    "            coordinates = [coordinates]    \n",
    "                         \n",
    "        #MultiPolygon is used to represent multiple polygons bbox and country     \n",
    "        search_parameters[\"intersects\"] = {\n",
    "            \"type\": \"MultiPolygon\", \n",
    "            \"coordinates\": coordinates\n",
    "        }\n",
    "        \n",
    "    search = catalog.search(**search_parameters)\n",
    "    items = search.item_collection()\n",
    "\n",
    "    return items\n",
    "\n",
    "# Use search_catalog function with a single variable \"region\" for bbox and country name\n",
    "result = search_catalog(region=region, date_period=date_period)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of items for input: {len(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9e82c-293f-4cdb-a263-314dfdd0a57e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process queried data into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0fb268-cde7-49f9-9787-89e6e3f2fa04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_links = [item.assets['ch4'].href for item in result]\n",
    "item_links\n",
    "\n",
    "f = fsspec.open_files(item_links)\n",
    "f = [file.open() for file in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ebc0c-a4fb-4b1e-b74e-427eb003cd50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = [xr.open_dataset(nc_file, group=\"PRODUCT\", engine=\"h5netcdf\") for nc_file in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03465356-b0e9-4948-b9a7-a0f8ee8aafb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = xr.open_mfdataset(f, group=\"PRODUCT\", engine=\"h5netcdf\", concat_dim=\"time\", combine='nested', join=\"outer\") \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f365ada-ba16-4a43-bf4e-19c59145f708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group datasets with similar time\n",
    "d_g = d.methane_mixing_ratio_bias_corrected.groupby(\"time\")\n",
    "d_g.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655047ea-4fa0-4ad8-8e21-2bdf71b0d1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_g[np.datetime64('2023-08-20T00:00:00.000000000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc69b1a-39a9-492a-8fd9-b22cd36a32ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for date, dataset in d_g:\n",
    "    # Initialize the map\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    continent_borders = world.dissolve(by='continent')\n",
    "    continent_borders.boundary.plot(ax=ax, linewidth=1, color='black')\n",
    "    fig.colorbar(colormesh, pad=0.05, shrink=0.35, label=\"methane (mol/m2)\")\n",
    "    plt.title(str(date))\n",
    "    ax.set_xlim(ROI_bbox[0], ROI_bbox[2])\n",
    "    ax.set_ylim(ROI_bbox[1], ROI_bbox[3])\n",
    "\n",
    "    for time in dataset:\n",
    "        # Extract the relevant data (assuming the variable name is 'methane_mixing_ratio_bias_corrected')\n",
    "        data = time.values #print(data.values)\n",
    "        lon = time.longitude.values\n",
    "        lat = time.latitude.values\n",
    "\n",
    "        # Calculate vmin and vmax for color normalization\n",
    "        vmin, vmax = np.nanpercentile(data, [1, 99])\n",
    "\n",
    "        # Plot the data\n",
    "        norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "        colormesh = ax.pcolor(lon, lat, data, cmap=\"Spectral_r\", norm=norm, transform=ccrs.PlateCarree(), alpha=0.9, rasterized=True)\n",
    "        plt.savefig(\"output/concentration_map\" + str(date) + \".jpg\")\n",
    "        \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c5eac-c7c2-4c0d-b0dd-e13073a86e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "frames = [Image.open(image) for image in glob.glob(f\"output/*.jpg\")]\n",
    "frame_one = frames[0]\n",
    "frame_one.save(\"time_series.gif\", format=\"GIF\", append_images=frames,\n",
    "           save_all=True, duration=1500, loop=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
